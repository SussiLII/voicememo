I would say you mentioned the deep seek moment and I do think deep seek is definitely winning the hearts of the people who work on open weight models because they share these as open models winning I think has multiple time scales to it we have today we have next year we have in 10 years one thing I know for sure is that I don't think nowadays 2026 that there will be any company who is let's say having access to a technology that no other company has access to and that is mainly because researchers are frequently changing jobs, changing labs, they rotate. So I don't think there will be... clear winner in terms of technology access however i do think there will be uh the differentiating factor will be budget and hardware constraints so i don't think the ideas will be proprietary but the way or the resources that are needed to implement them and so i don't see currently take it all scenario where a winner takes it all i can't see that at the moment uh nathan what do you think you see the labs put different energy into what they're trying to do and i think to demarcate the point in time when we're recording this um the hype over anthropics cloud opus 4.5 model has been absolutely insane which is just i mean i've used it and built stuff in the last few weeks and it's it's almost gotten to the point where it feels like a bit of a meme in terms of the hype and it's kind of funny because this is very organic and then if we go back a few months ago we can get the release date and the notes is Gemini 3 from Google got released and it seemed like the marketing and just like wow factor of that release was super high but then at the end of November Claude Opus 4.5 was released and the hype has been growing but Gemini 3 was before this and it kind of feels like people don't really talk about it as much even though when it came out everybody was like this is Gemini's moment to retake kind of Google's structural advantages in AI and Gemini 3 is a fantastic model and I still use it it's just kind of differentiation is lower and I agree with Sebastian what you're saying with all these like the idea space is very fluid but culturally anthropic is known for betting very hard on code which is called code thing is working out for them right now so I think that even if the ideas flow pretty freely so much of this is bottlenecked by human effort and kind of culture of organizations where anthropic seems to at least be presenting as the least chaotic is a bit of an advantage, and if they can keep doing that for a while. But on the other side of things, there's a lot of ominous technology from China where there's way more labs than DeepSeq. DeepSeq kicked off a movement within China, I say kind of similar to how ChatGPT kicked off a movement in the US where everything had a chatbot. There's now... Tons of tech companies in China that are releasing very strong frontier open weight models to the point where I would say that DeepSeq is kind of losing its crown as the preeminent open model maker in China and the likes of Z.AI with their GLM models, Minimax's models, Kimmy Moonshot, especially in the last few months, has shown more brightly. The new DeepSeq models are still very strong. But that's kind of a, it could look back as a big narrative point where in 2025 DeepSeat came and then kind of provided this platform for way more Chinese companies that are releasing these fantastic models to kind of have this new type of operation. So these models from these Chinese companies are open weights. And depending on this trajectory, business models that these American companies are doing could be at risk. But currently, a lot of people are paying for AI software. China and other parts of the world, people don't pay a lot for software. So some of these models like DeepSeek have the love of the people because they are open-weight. How long do you think the Chinese companies keep releasing open-weight models? I would say for a few years. I think that, like in the U.S., there's not a clear business model for it. I have been writing about open models for a while, and these Chinese companies have realized it, so I get inbound from some of them. And they're smart and realize the same constraints, which is that a lot of U.S. companies Tech companies and other IT companies won't pay for an API subscription to Chinese companies for security concerns. This has been a longstanding habit in tech. And the people at these companies then see open-weight models as an ability to influence and take part of a huge growing AI expenditure market in the U.S. And they're very realistic about this. And it's working for them. And I think that the government will see that that is happening. a lot of influence internationally in terms of uptake of the technology so there's going to be a lot of incentives to keep it going but building these models and doing the research is very expensive so at some point I expect consolidation but I don't expect that to be a story of 2026 where there will be more open model builders throughout 2026 than there were in 2025 and a lot of the notable ones will be in China. You were going to say something? to some extent yes but we also have to consider though they are still i would say slightly ahead and the other ones it's not that deep seek got worse it's just like the other ones are using the ideas from deep seek for example you mentioned kimmy same architecture they're training it and then again we have this leapfrogging where they might be at some point in time a bit better because they have the more recent model and i think this comes back to the other one comes in and the recent most recent model is probably always the best model yeah we'll also see that chinese companies have different incentives so like deepseek is very secretive where some of these startups are like the minimax's ai's of the world those do literally have file ipo paperwork and they're trying to get western mindshare and do a lot of outreach there so i don't famously is built by a hedge fund, High Flyer Capital. And we don't know exactly what they, we don't know what they use the models for or if they care about this. They're secret in terms of communication. They're not secret in terms of the technical reports that describe how their models work. They're still open on that front. And we should also say on the Opus 45 hype, there's the layer of something being the darling of the ex echo chamber on twitter echo chamber and the actual amount of people that are using the model i think it's probably fair to say that chat gpt and gemini are focused on the broad user base that just want to solve problems in their daily lives and that user base is gigantic so the hype about the coding may not be representative of the actual use i would say also are like you said name recognition brand and stuff but also muscle memory almost where um you know like jgpd has been around for a long time people just got used to using it and it's kind of like it's like a flywheel they recommend it to other users and that stuff one interesting point is also the customization of lms for example jgpd has a memory feature right and personal stuff but i don't know if you want to use that same thing at work you know because that's the boundary between private and work if you're working at a company they might not allow that you may not want that and i think that's also an interesting point where you might have multiple subscriptions one one is just clean code it keeps has nothing of your personal images that you hobby projects in there it's just like the work thing and then the other one is your personal thing so i think that's also something where two different use cases and it doesn't mean one it's i think the future is also question of are you willing to bet on Gemini over TachyBT which I would say in my gut feels like a bit of a risky bet because OpenAI has been the incumbent and there's so many benefits to that in tech and I think that momentum if you look at 2025 was on Gemini's side but they were starting from such a low point I think RIP Bard and these earlier attempts of getting started I think Huge credit for them for powering through the organizational chaos to make that happen. But also it's hard to bet against OpenAI because they always come off as so chaotic, but they're very good at landing things. And I think personally, I have very mixed reviews of GPT-5, but it had to have saved them so much money with the highlight feature being a router where most users are no longer... or GPU costs as much. So I think it's very hard to dissociate the things that I like out of models versus the things that are going to actually be a general public differentiator. What do you think about 2026? Who's going to win? I'll say something even though it's risky. I will say that I think Gemini will continue to take progress on ChatGPT. I think Google Scale, when both of these are operating, at such extreme scales and like Google has the ability to separate that research and product a bit better. We hear so much about AI being chaotic operationally and chasing the high impact thing, which is a very startup culture. And then on the software and enterprise side, I think Anthropic will have continued to success as they, again and again been set up for that and obviously google's cloud has a lot of offerings but i think this kind of like gemini name brand is important for them to build and google's cloud will continue to do wells but that's kind of a more complex thing to explain in the ecosystem because that's the likes of Azure and AWS rather than on the model provider side. So infrastructure, using GPUs, do you have an advantage? Largely because the margin on NVIDIA chips is insane and Google can develop everything from top to bottom to fit their stack and not have to pay This margin and they've had a head start in building data centers. So all of these things that have old highly times and very hard margins on high costs. Google has just kind of a historical advantage there. And if there's going to be a new paradigm, it's most likely to come from open AI where they're kind of their research division again and again is kind of shown. to land a new research idea or a product. I think like deep research, some are O1 thinking models, like all of these definitional things have come from OpenAI and that's got to be one of their top traits as an organization. So it's kind of hard to bet against that, but I think a lot of this year will be about scale and optimizing. what can be described as low-hanging fruit in models. And clearly, there's a trade-off between intelligence and speed. This is what JGPT-5 was trying to solve behind the scenes. It's like, do people actually want intelligence to broad public, or do they want speed? think it's a nice variety actually or the option to have a toggle there i mean first for my personal usage most of the time when i look something up i use jgbt to ask a quick question get the information i want it fast for you know most daily tasks i use the quick model nowadays i think the auto mode is pretty good where you don't have to specifically say thinking or you know non-thinking and stuff then again i also sometimes want the pro mode what i do is when i have something written i put it into check is all my references correct are all my thoughts correct uh did i make any formatting mistakes and are the figure numbers wrong or something like that and i don't need that right away it's something okay i finish my stuff maybe have dinner let it run come back and go through this and i think see this is where i think it's important to have the I'm like saying over here, I'm losing my mind that you use the router and the non-thinking model. I'm like, how do you live with that? That's like my reaction. I've been heavily on TrajPT for a while. never touched five non-thinking i find that its tone and then its propensity of errors it's just like the higher likelihood of errors some of this is from back when openai released 03 which was the first model to do this deep search and find many sources and integrate them for you so i became habituated with that so i will only use gpt 5.2 thinking or pro when i'm finding any sort of information query for work whether that's a p paper or some code reference that I found and it's just like I will regularly have like five pro queries going simultaneously each looking for one specific paper or feedback on the equation or something I have a fun example of where I just needed to answer as fast as possible for this podcast before I was going on the trip I have a local GPU running at home and I wanted to run a long oral experiment and usually I also unplug things because you never know if you're not at home you don't want to it was like my wife was already in the car and it's like oh dang and then basically i wanted as fast as possible a bash script that runs my different uh experiments in the information I learned how to use the bash interface or bash terminal, but in that moment I just needed like 10 seconds to give me the command. It was a hilarious situation, but yes, what did you use? So I did the non-thinking fastest model. It gave me the bash command to chain different scripts to each other. And then the thing is like you have the T thing where you want to route this to a log file. Top of my head, I was just like, in a hurry, I could have thought about it myself. By the way, I don't know if this is a representative case, white weight in the car, you have to run, you have to generate a badge, it sounds like a movie. I use Gemini. So I use thinking for all the information stuff, and then Gemini. sometimes google which is like it's good at explaining things and i trust that it has this kind of background of knowledge and it's simple and the gemini app has gotten a lot better and it's good for that sort of things and then for code and any sort of philosophical discussion i use claude opus 4.5 also always with extended thinking difference time scaling is just a way to make the models marginally smarter and I will always edge on that side when the progress is very high because you don't know when that'll unlock a new use case and then sometimes use grok for real-time information or finding something on AI Twitter that I knew I saw and I need to dig up and I just fixate it on. Although when Grok 4 came out, the Grok 4 was super heavy, which was like their pro variant, was actually very good. And I was pretty impressed with it. And I just kind of like muscle memory, lost track of it with having the ChatGPT app open. So I use many different things. Yeah, I actually do use Grok 4 heavy for debugging stuff. for like hardcore debugging and the other ones can't solve it. I find that it's the best. And I, it's interesting because you say ChatGPG is the best interface for me for that same reason, but this could be just momentum. Gemini is the better interface for me. I think because I fell in love with their best needle in the haystack if I ever put something that has a lot of context but I'm looking for a very specific kind of information make sure it tracks all of it I find at least the Gemini for me has been the best so it's funny with some of these models if they win your heart over for one particular feature at one on a one particular day for that particular query that prompt You're like, this model is better, and so you'll just stick with it for a bit until it does something really dumb. There's like a threshold effect, some smart thing, and then you fall in love with it, and then it does some dumb thing, and you're like, you know what, I'm going to switch to Tri-Claw and Uncharted GPT and all that kind of stuff. Be like, you use it until it breaks, until you have a problem, and then you change the alarm. And I think it's the same how we use anything, like favorite text editor, operating systems, or the browser. I mean, there are so many browser options, Safari, Firefox, Chrome. extensions you want to use, and then you switch. But I don't think there's anyone who types the same thing, like the website, into different browsers and compares them. You only do that when the website doesn't render, if something breaks, I think. So that's a good point. I think you use it until it breaks, and then you explore other options, I think. On the long context thing, I was also a Gemini user for this, but the GPT 5.2 release blog had crazy long context scores, where a lot of people were like, did they just figure out somehow your model update. So it's also very hard to keep track of all of these things. But now I look more favorably at GPT 5.2's long context. So it's just kind of like, how do I actually get to testing this never ending battle? It's interesting that none of us talked about the Chinese models from a user usage perspective. What does that say? Does that mean the Chinese models are not as good? Or does that mean we're just very biased? platform. So I think the open models, they are more known for the open weights, not the platform yet. There are also a lot of companies that are willing to sell you an open model inference at a very low cost. I think like OpenRouter, it's easy to do the look at on deep seek, on perplexity. I think all of us sitting here are like, we use OpenAI GPT-5 Pro consistently. We're all willing to pay for the marginal intelligence gain. And anyone that's, like, these models from the US are better in terms of the outputs. I think the question is, will