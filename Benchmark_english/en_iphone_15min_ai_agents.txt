is the next-gen AI agents and developments. It's not really for operators, unfortunately. We're trying to kind of cover the land, and then we're working What is one of the most exciting spaces in AI these days, I would say, is AI Agents. This is kind of like a controversial opinion, maybe in 2024, but in 2025, it's going to be a very strong, as a topic, area of AI and AI is going to be about the use of AI. So it seems like it's kind of like an accepted norm that AI Agents are here to stay, and we should just adapt our use cases and adapt our use of AI. No, similar to other cases in AI, everything has like a big definition when you ask different people. Like if I assume that one is AGI, probably I'm not really going to know what AGI is. So I just want to kind of get the idea of what AGI is. like a non-agentic setup would be like a zero-chart prompting where you just end up with this query and it ends up giving you like one pass over. This is what I think is going to be like a good idea. What an agentic flow would look like is probably it's going to ask you for more details like, hey, when are you planning to travel? Or how many people are traveling? What's the budget? And then kind of get more information based on the things which the model has not been trained on. because most of these models have like some limitation and can not get enough of the data and that's where like the agency workforce comes in. So it's kind of like adding whatever the limitations or super limitations of existing LLMs are and then using all access, like access to other people's other resources that are there in the group and then just bringing in all those pieces of information. So the final output that the LLM gets is much higher quality and better addresses their needs case. Now, I think we have kind of given benchmarks enough. So if we ask LLM to just write us a new solid function right now, how well does it do? What you see are as a takeaway from this product, like the zero-sharp prompting for all GPs in the environment are pretty low in accuracy, but as soon as you include some of the AI-based recipes on top of it, the numbers basically shrink. Ignore the absolute numbers, but the takeaway from this is that, okay, there is a lot more that you can extract by just tweaking the way in which we're prompting the M&M's and maybe using the output from these M&M's. And this seems like a trend which continues to hold across all the M&M's, doesn't matter which company it's coming from. What I've tried to do is pretty much trying to understand what are the major design patterns when it comes to academia industry, and try to look at what are the major design patterns that people use when they're designing in different platforms. Seems like there are four main trends. One is reflection, the other is review, the third is planning, and the fourth is multi-agent collaboration. I'm going to go over each one of them in a slightly handily way, but if some more designers are going to be happy. Reflection. So what we mean by that, initiating, this problem has gone down. What we know is just including some things in it. really parallel when it comes to syntax errors in coding. Because again, it has such impromptu models that you try to get some code out of code from the model again and be like, hey, are you sure this syntax is right? And in case, there are cases in which it is true. do you use something again interesting where uh now the models have become really really good in understanding what the limitations are historically they were of the opinion that oh we have to answer everything but then they didn't know when to say no now if you ask the question that hey uh can you craft me a personalized investment knows that whatever information that has been taken as part of the training is given in terms of . So it knows, OK, if I have access to a set of tools, or if I have access to a given piece, I can go online, get what the latest things are, get what the latest things are, and come up with a good form of character. So I'll give it back to you. Planning is, again, something really interesting, which is, it boils down to how your prompting data ends. I guess, pretty much in 2023, there was a lot of work around, oh, this is the best recipe on how to prompt the other end. And in most cases, the prompting was that, pick up the prompting process steps, and then prompt the other end. Now, in the agent-tagged workflows, we see that instead of making it a user problem, who would ask the question in the right way, we can kind of base this in our draft up there, where you kind of base the problem with sub-competents, and then address each of those sub-competents in the right way. For example, a user asks, and then we design a posting website with a blog about that information in the portfolio. Now, there's a lot of information that is baked in that doesn't have links to our home page. It needs to have that fact in it. But instead of making it a user problem to prompt the algorithm to do x, to do y, to do z, and then switch it together, we're kind of giving them metadata, or the meta-influenced meta-quade, as the name of it, and maybe the abstraction there, base it down on some components, and then it goes, and then we do all these things on its own. Multi-agent collaboration, this is pretty much like a design room that we've seen kind of work really well. When you have a system prompt, you can prompt the LLMs to identify or kind of integrate a person. And what we've seen is that it works really well. So if you can come up with a good example, that you can have two different personas. Maybe one persona is of an engineer who's writing the book, and the other persona is of a senior engineer or a person who's just evaluating the book. And at least more weeks in the system from stage, and then evaluating the offers. So we've seen it work really, really well. It kind of also limits the scope of what the LLM is doing for that particular query. So the overall quality of the output is of . So in this example, we're asking for a code from . It's kind of a weight problem. But then we end up having a different for the LLM queries. And then each of the has its specific that it is trying to solve. And that's where we can . Now, I am not making a big use case, but I do kind of think that how all these underlying patterns can come together to solve one problem at a time. So if you have a retail manager who wants to have a customer across the store section and understand what the owner is trying to do, high-grade expensive sensors and cameras, then have it in both fields, then identify, okay, this person needs to be tracked, have it custom-cared, okay, this is a face-tracking thing happening, need to track that person independently, and then have maybe some e-commerce data on top of it. Now, if we use these identity AI workflows, again, a lot of work needs to be done and everything. I'm just assuming that everything just goes outside of the box. It's not the case right now, but probably it's going to be the case in a couple of months. You can think about reflection where, oh, we have these editable processes that down the fridge and are independent of customer paths. Maybe we can is that it will be made in the actual path identification so that it tracks these things even if there's some occlusion when the person is like walking across the street. So like essentially being on the curve for tracking movement of people can also kind of improve the overall accuracy and there's all these like soft spots that we've kind of encountered like on the genitals, the poster side. do use something interesting, where we are noticing a larger trend that more and more people to become accessible for these beliefs to work with. I think the trend that we see currently going forward is that there's no much better understanding of what people use in what scenario. There might be some redundancy that people show. And so in some cases, it might just end up sending it to something and sending it to Google. But again, making these things into the platform where it seems that they're . Now, planning is, again, something . you have to do these things in this specific scenario, having a good planning layer automatically breaks these things down. And because it's already having a separate layer, it kind of serves as like a self-healing tool where you can notice that in some of the cases, the metrics that we're getting are not down, right? It maybe ends up breaking down that subset of the way much more granular it is, and ended up solving And then . Now, one-agent collaboration, it's more like kind of bringing everything together. Maybe you did everything right, but the final visualization that I created that might be perfect or something, which I should be logging that might be logged correctly. Again, I'd have to view the initial layers where the initial mapping code was written. So the persona of the final UI or UI layer can just say, hey, this information seems to be cluttered and I'm not able to So coming to the key trends, what we're seeing, I think conversational inputs are here to stay. The definition of chatbot is sort of rapidly moving. I guess that was the main common thread. What we used to perceive as a chatbot is kind of changing. And I think previous speakers also. So what we used to traditionally think of as a traditional chatbot seems to be evolving. I think the token generation costs are going to come down, as we can see, especially because a lot of these AI agent workloads are token heavy. There's a lot of information happening across all the layers. It just seems like a trend that basically can and seems like the overall cost of this is going to be down. Brittle workflows, I think the agent workflows remain very fragile, especially because they're just latching on to these . I could probably see a trend where we have more specific which are catered to maybe a specific use case. Like if maybe a model is just really, really good at understanding e-commerce, which is really good at understanding and so on. Beyond text, I think the emergence of word boxes will begin to influence on the domain. This is kind of related to something more general. For example, autonomous driving, where a lot of innovation has been made with these LLMs. For example, when it comes to these . So we could actually see these LLMs also serving as a world market space where things which we now there's still some key challenges and open issues i think the first one is evaluation and benchmarking pretty much every speaker over here is kind of happy with that like benchmarks are quite written we all agree that it's pretty much kind of came quite easy and a hard challenge. In most cases, what I personally have seen to work really well is that folks on a previous case have really well-valued evals on what is the expected behavior, and then come in with insight on that. Again, the eval should not be something that you just freeze in time. It should be something that you continue to target upon. As soon as you hit 90% or even 30%, that doesn't mean that you're freezing. It just means that the eval that we will discriminate on, they really . safety and alignment agent. Workflows are pretty much like a They definitely pose a lot of risks, especially when they go out and then work properly with the open code. Like, maybe you can just write an HTML code that just goes into this bunch of forms online. So other platforms which have these forms, which are actually giving you information, where you can get information from actual users, might just get spammed with a lot of these individual forms just filling in random garbage. Safety, again, is an interesting aspect, because people are willing to now have their bed time with their patients. So at what point do you want to give you the benefit of the action is, again, a really critical decision that needs to be made. It will be very dependent on what you do and the progress. So probably the answer to this question is really important.